{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gradio as gr\n",
    "from torchvision import models\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset and Data Loaders\n",
    "\n",
    "**Image Transformations:**\n",
    "\n",
    "- Defines a series of transformations (transform) to be applied to the images, including resizing them to 128x128 pixels and converting them to tensors using ToTensor().\n",
    "\n",
    "**Loading Datasets:**\n",
    "\n",
    "- Loads the training dataset from the directory 'tree_train_set' and the validation dataset from 'tree_test_set' using ImageFolder. The specified transformations are applied to each image as they are loaded.\n",
    "\n",
    "**Display Classes:**\n",
    "\n",
    "- Prints the names of the classes (categories) in the training dataset using train_data.classes.\n",
    "\n",
    "**Creating Data Loaders:**\n",
    "\n",
    "- Creates data loaders (train_loader and val_loader) for the training and validation datasets, respectively, with a batch size of 16. The training data is shuffled, while the validation data is not.\n",
    "\n",
    "**Display Sample Counts:**\n",
    "\n",
    "- Prints the number of samples in the training and validation datasets using len(train_data) and len(val_data).\n",
    "\n",
    "\n",
    "**`Overall, this code prepares the image datasets for training a machine learning model, ensuring images are the correct size and in tensor format for processing.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['birch', 'juniper', 'maple', 'pine', 'spruce']\n",
      "Number of training samples: 106\n",
      "Number of validation samples: 30\n"
     ]
    }
   ],
   "source": [
    "# Transformations (from your lab)\n",
    "transform = Compose([Resize((128, 128)), ToTensor()])\n",
    "\n",
    "# Load the dataset\n",
    "train_data = ImageFolder(root='tree_train_set', transform=transform)\n",
    "val_data = ImageFolder(root='tree_test_set', transform=transform)\n",
    "print('Classes:', train_data.classes)\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: tree_test_set\n",
      "Number of files: 0\n",
      "Files: []\n",
      "--------------------------------------------------\n",
      "Directory: tree_test_set\\birch\n",
      "Number of files: 7\n",
      "Files: ['testBirch01-000.jpg', 'testBirch01-001.jpg', 'testBirch01-002.jpg', 'testBirch01-003.jpg', 'testBirch01-004.JPEG', 'testBirch01-005.JPEG', 'testBirch01-006.jpg']\n",
      "--------------------------------------------------\n",
      "Directory: tree_test_set\\juniper\n",
      "Number of files: 4\n",
      "Files: ['testJuniper02-000.jpg', 'testJuniper02-001.jpg', 'testJuniper02-002.jpg', 'testJuniper02-003.jpg']\n",
      "--------------------------------------------------\n",
      "Directory: tree_test_set\\maple\n",
      "Number of files: 8\n",
      "Files: ['testMaple03-000.jpg', 'testMaple03-001.jpg', 'testMaple03-002.jpg', 'testMaple03-003.jpg', 'testMaple03-004.jpg', 'testMaple03-006.jpg', 'testMaple03-007.jpg', 'testMaple03-008.jpg']\n",
      "--------------------------------------------------\n",
      "Directory: tree_test_set\\pine\n",
      "Number of files: 5\n",
      "Files: ['testPine04-000.JPEG', 'testPine04-001.JPEG', 'testPine04-002.jpg', 'testPine04-003.jpg', 'testPine04-004.jpg']\n",
      "--------------------------------------------------\n",
      "Directory: tree_test_set\\spruce\n",
      "Number of files: 6\n",
      "Files: ['testSpruce05-000.jpg', 'testSpruce05-001.jpg', 'testSpruce05-002.JPEG', 'testSpruce05-003.JPEG', 'testSpruce05-004.JPEG', 'testSpruce05-005.JPEG']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "val_dir = 'tree_test_set'\n",
    "for root, dirs, files in os.walk(val_dir):\n",
    "    print(f\"Directory: {root}\")\n",
    "    print(f\"Number of files: {len(files)}\")\n",
    "    print(f\"Files: {files}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Pre-trained ResNet Model\n",
    "\n",
    "In this block, we load the pre-trained **ResNet18** model, which is a popular deep learning architecture known for its residual connections that help avoid the vanishing gradient problem in deep networks.\n",
    "\n",
    "- **models.resnet18()**: This function loads the **ResNet18** architecture from the **torchvision** library.\n",
    "\n",
    "- **weights=models.ResNet18_Weights.DEFAULT**: This specifies that we are using the pre-trained weights provided by torchvision. These weights are trained on a large-scale dataset like ImageNet, allowing us to benefit from a model that has already learned useful features.\n",
    "\n",
    "- **.to(device)**: This moves the model to the specified device (usually a GPU or CPU). If a GPU is available, the model will run on it for faster computations.\n",
    "\n",
    "By using this pre-trained model, we leverage the knowledge it has already learned and adapt it to our specific task (transfer learning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained ResNet model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code modifies the final fully connected layer of a pre-trained neural network model for transfer learning.\n",
    "\n",
    "- **model.fc:** This accesses the final fully connected layer of the model, which is typically used to output class predictions.\n",
    "\n",
    "- **nn.Linear(512, 5):** This replaces the existing final layer with a new linear layer that takes 512 input features (the output size from the previous layer) and produces 5 output features, corresponding to the 5 classes in the Trees dataset.\n",
    "\n",
    "- **.to(device):** This moves the modified layer to the specified device (CPU or GPU) for computation.\n",
    "\n",
    "**`In summary, this code adapts the pre-trained model to classify images into 5 specific classes related to trees, making it suitable for the new dataset.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the final fully connected layer for transfer learning (assuming 5 classes for the Trees dataset)\n",
    "model.fc = nn.Linear(512, 5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code sets up the components needed for training a neural network:\n",
    "\n",
    "**Loss Function:**\n",
    "\n",
    "- **criterion = nn.CrossEntropyLoss():** This defines the loss function as Cross Entropy Loss, which is used for multi-class classification tasks. It calculates how well the model's predicted class probabilities match the true class labels, helping to guide the training process by providing feedback on errors.\n",
    "\n",
    "**Optimizer:**\n",
    "\n",
    "- **optimizer = optim.Adam(model.parameters(), lr=0.001):** This initializes the Adam optimizer, which is used to update the model's weights during training.\n",
    "\n",
    "- **model.parameters()** passes the model's parameters (weights and biases) to the optimizer.\n",
    "\n",
    "- **lr=0.001** sets the learning rate, determining the step size for weight updates. A learning rate of 0.001 is commonly used to ensure stable and effective training.\n",
    "\n",
    "**`In summary, this code prepares the loss function and optimizer, essential for training the neural network effectively.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "This code defines two functions for training and validating a machine learning model.\n",
    "\n",
    "- **train():**\n",
    "\n",
    "- Sets the model to training mode.\n",
    "- Loops through the training data (loader), performs forward passes to compute predictions, calculates the loss, and uses backpropagation to update the model's weights with the optimizer.\n",
    "- Tracks the training loss and accuracy for the current epoch and prints them at the end.\n",
    "\n",
    "### Validation Loop\n",
    "\n",
    "- **validate():**\n",
    "\n",
    "- Sets the model to evaluation mode (no gradient calculations).\n",
    "- Loops through the validation data, performs forward passes to get predictions, calculates the loss, and measures the accuracy.\n",
    "- Tracks and prints the validation loss and accuracy after going through the entire validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "\n",
    "    print(f\"Train Loss: {epoch_loss}, Train Accuracy: {epoch_accuracy}%\")\n",
    "\n",
    "# Validation loop\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "\n",
    "    print(f\"Validation Loss: {epoch_loss}, Validation Accuracy: {epoch_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "This code trains a machine learning model for 10 epochs and evaluates its performance after each epoch.\n",
    "\n",
    "- num_epochs = 10: The number of times the model will go through the training data.\n",
    "- for epoch in range(num_epochs):: A loop that runs the training and validation process 10 times (one for each epoch).\n",
    "- train(): A function that handles training the model using the training dataset (train_loader), updating weights with the optimizer, and calculating the loss using the criterion.\n",
    "- validate(): A function that evaluates the model on the validation dataset (val_loader) to check its performance without updating weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.04510910855606198, Train Accuracy: 99.05660377358491%\n",
      "Validation Loss: 1.074363797903061, Validation Accuracy: 66.66666666666667%\n",
      "Epoch 2/10\n",
      "Train Loss: 0.03425344691744873, Train Accuracy: 99.05660377358491%\n",
      "Validation Loss: 1.3086349964141846, Validation Accuracy: 66.66666666666667%\n",
      "Epoch 3/10\n",
      "Train Loss: 0.025374088935287937, Train Accuracy: 99.05660377358491%\n",
      "Validation Loss: 1.5804842412471771, Validation Accuracy: 60.0%\n",
      "Epoch 4/10\n",
      "Train Loss: 0.05217774812730828, Train Accuracy: 98.11320754716981%\n",
      "Validation Loss: 1.0634645521640778, Validation Accuracy: 70.0%\n",
      "Epoch 5/10\n",
      "Train Loss: 0.01924234246169882, Train Accuracy: 99.05660377358491%\n",
      "Validation Loss: 0.6944030523300171, Validation Accuracy: 80.0%\n",
      "Epoch 6/10\n",
      "Train Loss: 0.035229971898453574, Train Accuracy: 99.05660377358491%\n",
      "Validation Loss: 0.7221062481403351, Validation Accuracy: 80.0%\n",
      "Epoch 7/10\n",
      "Train Loss: 0.08918664684253079, Train Accuracy: 97.16981132075472%\n",
      "Validation Loss: 0.9105867445468903, Validation Accuracy: 76.66666666666667%\n",
      "Epoch 8/10\n",
      "Train Loss: 0.007589060114696622, Train Accuracy: 100.0%\n",
      "Validation Loss: 1.3926461935043335, Validation Accuracy: 70.0%\n",
      "Epoch 9/10\n",
      "Train Loss: 0.11688902987433332, Train Accuracy: 96.22641509433963%\n",
      "Validation Loss: 1.055175930261612, Validation Accuracy: 70.0%\n",
      "Epoch 10/10\n",
      "Train Loss: 0.023826922472965504, Train Accuracy: 100.0%\n",
      "Validation Loss: 0.7788280546665192, Validation Accuracy: 73.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 10 epochs (you can increase the epochs as needed)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    validate(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save the model to disk \n",
    "torch.save(model.state_dict(), '(1)resnet18_tree_recognition.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Käyttäjä\\AppData\\Local\\Temp\\ipykernel_2812\\510917705.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('(1)resnet18_tree_recognition.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://7ac1ae9529b955f39e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7ac1ae9529b955f39e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Lataa aiemmin treenattu malli\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "# Muokkaa mallin viimeistä kerrosta, jos luokkien määrä on eri\n",
    "num_classes = 5\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Lataa tilatiedot (aiemmin tallennetusta tiedostosta)\n",
    "model.load_state_dict(torch.load('(1)resnet18_tree_recognition.pth'))\n",
    "model.eval()  # Aseta malli arviointitilaan\n",
    "\n",
    "# Määrittele kuvan muunnos, jota käytetään ennustamiseen\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Sama koko kuin koulutuksessa\n",
    "    transforms.ToTensor()  # Muunna tensoriksi\n",
    "])\n",
    "\n",
    "# Ennustusfunktio\n",
    "def predict(image):\n",
    "    # Muunna kuva tensoriksi ja lisää batch-dimensio\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Mallin ennustus\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "        # Softmax, jotta saadaan todennäköisyydet eri luokille\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        # Muunna todennäköisyydet numpyksi\n",
    "        scores = probabilities.squeeze().cpu().numpy()\n",
    "\n",
    "    # Palauta todennäköisyydet ja luokkien nimet\n",
    "    class_names = train_data.classes  # Luokat koulutusdatasta\n",
    "    class_scores = {class_names[i]: float(scores[i]) for i in range(len(class_names))}\n",
    "    \n",
    "    return class_scores  # Palauta luokat ja todennäköisyydet\n",
    "\n",
    "# Gradio-käyttöliittymän luominen\n",
    "image_input = gr.Image(type=\"pil\")  # Uudempi syntaksi kuvan syötteelle\n",
    "label_output = gr.Label(num_top_classes=3)  # Uudempi syntaksi tulosteen luokittelulle\n",
    "\n",
    "# Luo käyttöliittymä Gradiolla\n",
    "gr_interface = gr.Interface(\n",
    "    fn=predict,  # Ennustusfunktio\n",
    "    inputs=image_input,  # Syöte on kuva\n",
    "    outputs=label_output,  # Tuloste on luokat ja todennäköisyydet\n",
    "    title=\"Tree Species Recognition\",  # Käyttöliittymän otsikko\n",
    "    description=\"Upload a tree image to classify its species.\"  # Kuvaus\n",
    ")\n",
    "\n",
    "# Käynnistä Gradio-käyttöliittymä\n",
    "gr_interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: birch\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Function to perform inference on a single image\n",
    "def infer(model, image_path, transform, device):\n",
    "    # Load the image and convert it to RGB (3 channels)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = output.max(1)\n",
    "    \n",
    "    return predicted.item()\n",
    "\n",
    "# Class names are based on the order printed from train_data.classes\n",
    "class_names = ['birch', 'juniper', 'maple', 'pine', 'spruce']\n",
    "\n",
    "# Path to the test image\n",
    "image_path = 'tree_test_set/pine/testPine04-004.jpg'  # Adjust the path as needed\n",
    "\n",
    "# Run inference\n",
    "predicted_class = infer(model, image_path, transform, device)\n",
    "print(f'Predicted class: {class_names[predicted_class]}')\n",
    "\n",
    "# Path to the test image\n",
    "# image_path = 'rps-test-set/rock/testrock01-00.png'  # Ensure the path is correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions: 30\n",
      "Number of true labels: 30\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to get predictions for the entire validation set\n",
    "def get_all_predictions(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            all_preds.append(predicted.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Convert list of arrays to single numpy arrays\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Get predictions and true labels from validation data\n",
    "preds, labels = get_all_predictions(model, val_loader, device)\n",
    "# Print the shape of preds and labels\n",
    "print(f\"Number of predictions: {len(preds)}\")\n",
    "print(f\"Number of true labels: {len(labels)}\")\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Display the confusion matrix\n",
    "class_names = ['birch', 'juniper', 'maple', 'pine', 'spruce']  # Based on your dataset\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
